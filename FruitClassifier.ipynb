{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6956251-eb83-4483-aff8-5d150983fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8d3554c-0b7d-490f-a1b8-4893167afc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "dataset = \"/fruits-360_dataset_100x100\"\n",
    "train_path = basedir + dataset + \"/fruits-360/Training\"\n",
    "test_path = basedir + dataset + \"/fruits-360/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccdcd55d-56a6-414d-b7b6-2471b409a176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70491"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add all data in filename\n",
    "# def load_data(path):\n",
    "#     folders = [f for f in os.listdir(path)]\n",
    "#     images = []\n",
    "#     imglabels = []\n",
    "#     labels = [] \n",
    "#     yes = True\n",
    "#     for f in folders:\n",
    "#         labels.append(f)\n",
    "#         folder_path = os.path.join(path, f)\n",
    "#         cur_images = [(folder_path + \"/\" + img) for img in os.listdir(folder_path)]\n",
    "#         imglabels.extend(len(cur_images) * [f])\n",
    "#         images.extend(cur_images)\n",
    "#     return np.array(images), np.array(imglabels), labels\n",
    "\n",
    "# X_train, Y_train, labels = load_data(train_path)\n",
    "# X_test, Y_test, _ = load_data(test_path)\n",
    "# len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b9d6ad-be2d-4d7b-9961-7c9720b30c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#process Y's into number and prob distribution for loss function\n",
    "# Y_train_temp = np.zeros((len(Y_train),len(labels)))\n",
    "# Y_test_temp = np.zeros((len(Y_test),len(labels)))\n",
    "# for cnt, label in enumerate(labels):\n",
    "#     for i in range(len(Y_train)):\n",
    "#         if Y_train[i] == label:\n",
    "#             Y_train_temp[i][cnt] = 1 \n",
    "#     for i in range(len(Y_test)):\n",
    "#         if Y_test[i] == label:\n",
    "#             Y_test_temp[i][cnt] = 1\n",
    "# Y_train = Y_train_temp\n",
    "# Y_test = Y_test_temp\n",
    "# print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b77ffea9-1fbf-43dd-95b0-7ebd3397be43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle\n",
    "# trainp = np.random.permutation(len(X_train))\n",
    "# X_train = X_train[trainp]\n",
    "# Y_train = Y_train[trainp]\n",
    "# testp = np.random.permutation(len(X_test))\n",
    "# X_test = X_test[testp]\n",
    "# Y_test = Y_test[testp]\n",
    "# Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce52b5bf-4d5d-4254-879d-bbf4ba6982da",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m X_train \u001b[38;5;241m=\u001b[39m DataLoader(X_train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m X_test \u001b[38;5;241m=\u001b[39m DataLoader(X_test, batch_size\u001b[38;5;241m=\u001b[39mbatch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m X_train:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# batch_size = 256\n",
    "# image_height = 100\n",
    "# image_width = 100\n",
    "# num_channels = 3\n",
    "# transforms_data = transforms.Compose([transforms.ToTensor(),\n",
    "#                                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "#                                        transforms.Resize((image_height, image_width)),\n",
    "#                                        ])\n",
    "\n",
    "\n",
    "# X_train = DataLoader(X_train, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "# X_test = DataLoader(X_test, batch_size=batch_size * 2, shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319abd27-21ac-41cb-8b2d-54ba31ab8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((128,128)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03622f86-7eb8-46e3-80f2-a2ad2c4d30a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing dataset attempt #2\n",
    "# def prepare_dataset(base_dir, transform=None):\n",
    "#     dataset = []\n",
    "#     labels = sorted(os.listdir(base_dir))\n",
    "#     for cnt, label_name in enumerate(labels):\n",
    "#         folder_path = os.path.join(base_dir, label_name)\n",
    "#         if os.path.isdir(folder_path):\n",
    "#             for img in os.listdir(folder_path):\n",
    "#                 img_path = os.path.join(folder_path, img)\n",
    "\n",
    "#                 with Image.open(img_path) as curimg:\n",
    "#                     curimg = curimg.convert(\"RGB\")\n",
    "#                     if transform:\n",
    "#                         curimg = transform(curimg)\n",
    "#                 dataset.append((curimg, label_name))\n",
    "# train_data = prepare_dataset(train_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebbeabc3-c15d-4b18-aee7-a08c01c078a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using dataloader immediately\n",
    "\n",
    "trainfolder = ImageFolder(train_path, transform=ToTensor());\n",
    "testfolder = ImageFolder(test_path, transform=ToTensor());\n",
    "\n",
    "traindataloader = torch.utils.data.DataLoader(trainfolder, batch_size=128, shuffle=True)\n",
    "testdataloader = torch.utils.data.DataLoader(testfolder, batch_size=128, shuffle=True)\n",
    "X_train, Y_train = next(iter(traindataloader))\n",
    "X_test, Y_test = next(iter(testdataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6964aeed-bf28-44ee-805b-06ec626469c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea30ad-c5a4-4deb-b461-953c048753ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "        self.conv1 = nn.Conv2d(1,6,4)\n",
    "        self.conv2 = nn.Conv2d(6,16,4)\n",
    "        self.linear = nn.Linear(256, 10) \n",
    "    def forward(self,x):\\n\",\n",
    "        c1 = F.relu(self.conv1(x)) \n",
    "        l2 = F.max_pool2d(c1, (2,2))\n",
    "        c2 = F.relu(self.conv2(l2)) \n",
    "        l4 = F.max_pool2d(c2,(2,2))\n",
    "        l4 = torch.flatten(l4,1) \n",
    "        out = self.linear(l4)\\n\n",
    "        return out\\n\",\n",
    "model = ConvNet()\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
